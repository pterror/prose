model:
  hidden_channels: 256
  depth: 3
  pool_ratio: 0.5
  layer_type: GAT # or GCN

training:
  epochs: 50
  batch_size: 1 # Trajectory-based training processes one sample at a time
  lr: 0.001
  weight_decay: 0.0001
  gradient_accumulation_steps: 8 # Effective batch size = 8 trajectories
  warmup_epochs: 5 # Linear warmup from lr/10 to lr

data:
  train_dir: data/phase1_5/train
  val_dir: data/phase1_5/pilot
  vocabulary: data/phase1_5/vocabulary.json

# Corruption curriculum (auto-scheduled by epoch)
# Stage 1 (epochs 0-5):   20% corruption, keep structure
# Stage 2 (epochs 6-15):  50% corruption, keep structure
# Stage 3 (epochs 16-25): 75% corruption, keep structure
# Stage 4 (epochs 26-40): 90% corruption, no structure
# Stage 5 (epochs 41-50): 100% corruption (full generation)

logging:
  log_dir: runs
  checkpoint_dir: checkpoints
  save_every: 5 # Save checkpoint every N epochs
  log_every: 50 # Log metrics every N batches

device: cuda # or cpu
seed: 42
