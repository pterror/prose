model:
  hidden_channels: 256
  depth: 3
  pool_ratio: 0.5
  layer_type: GAT
  max_iterations: 5
  max_tests: 100  # Maximum number of tests for cross-attention
  max_nodes: 1000  # Maximum number of nodes for trace encoding
  num_attention_heads: 4  # Number of heads for cross-attention
  use_test_guidance: true  # Enable cross-attention guidance

training:
  epochs: 50
  batch_size: 1
  lr: 0.001
  weight_decay: 0.0001
  gradient_accumulation_steps: 8
  warmup_epochs: 5

# Scheduled sampling (same as baseline)
scheduled_sampling_max: 0.95
scheduled_sampling_warmup: 0.5

data:
  train_dir: data/phase1_5/train
  val_dir: data/phase1_5/pilot
  vocabulary: data/phase1_5/vocabulary.json

# IMPORTANT: test_feedback=None at iteration 0 to prevent one-shot dependency
# This forces the model to learn one-shot prediction without relying on test signals
# Cross-attention is only used for refinement iterations (1+)

logging:
  log_dir: runs/phase1_5_guided_fixed
  checkpoint_dir: checkpoints/phase1_5_guided_fixed
  save_every: 5
  log_every: 50

device: cuda
seed: 42
